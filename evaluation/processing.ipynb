{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datetime import datetime\n",
    "from kmodule.keystroke_module import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: kontrola bledow np. w konstruktorze klasy -?\n",
    "# zalozenie minimalnej dlugosci: 100 czy 150? (bo wynika ze w ciagu 6min z 1.datasetu najmniej to 107 i 117 po filtracji, reszta co najmniej 150 kikniec, srednio na osobe wychodzi 600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data - (1. dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\kmodule\\keystroke_module.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1.drop(columns=['file_2'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients with PD:  60\n",
      "Patients without PD:  56\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename1 = 'D:/studia_mgrEIM/master_diploma/data/neuroqwerty/MIT-CS1PD/GT_DataPD_MIT-CS1PD.csv'\n",
    "filename2 = 'D:/studia_mgrEIM/master_diploma/data/neuroqwerty/MIT-CS2PD/GT_DataPD_MIT-CS2PD.csv'\n",
    "path = 'D:/studia_mgrEIM/master_diploma/data/neuroqwerty/all/'\n",
    "\n",
    "data1 = nqDataset(filename1, filename2)\n",
    "data1.show_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "(116, 6)\n"
     ]
    }
   ],
   "source": [
    "data1.prepare_dataset(path, feature_extract=1)\n",
    "print(data1.features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "a = np.count_nonzero(np.isnan(data1.features))\n",
    "print(a)\n",
    "col_mean = np.nanmean(data1.features, axis=0)\n",
    "\n",
    "inds = np.where(np.isnan(data1.features))\n",
    "data1.features[inds] = np.take(col_mean, inds[1])\n",
    "b = np.count_nonzero(np.isnan(data1.features))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fold:  1\n",
      "{'0.0': {'precision': 0.5625, 'recall': 0.9, 'f1-score': 0.6923076923076923, 'support': 10}, '1.0': {'precision': 0.875, 'recall': 0.5, 'f1-score': 0.6363636363636364, 'support': 14}, 'accuracy': 0.6666666666666666, 'macro avg': {'precision': 0.71875, 'recall': 0.7, 'f1-score': 0.6643356643356644, 'support': 24}, 'weighted avg': {'precision': 0.7447916666666666, 'recall': 0.6666666666666666, 'f1-score': 0.6596736596736597, 'support': 24}}\n",
      "Number of fold:  2\n",
      "{'0.0': {'precision': 0.4, 'recall': 0.6666666666666666, 'f1-score': 0.5, 'support': 6}, '1.0': {'precision': 0.8461538461538461, 'recall': 0.6470588235294118, 'f1-score': 0.7333333333333334, 'support': 17}, 'accuracy': 0.6521739130434783, 'macro avg': {'precision': 0.6230769230769231, 'recall': 0.6568627450980392, 'f1-score': 0.6166666666666667, 'support': 23}, 'weighted avg': {'precision': 0.7297658862876254, 'recall': 0.6521739130434783, 'f1-score': 0.6724637681159421, 'support': 23}}\n",
      "Number of fold:  3\n",
      "{'0.0': {'precision': 0.7857142857142857, 'recall': 0.7857142857142857, 'f1-score': 0.7857142857142857, 'support': 14}, '1.0': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1-score': 0.6666666666666666, 'support': 9}, 'accuracy': 0.7391304347826086, 'macro avg': {'precision': 0.7261904761904762, 'recall': 0.7261904761904762, 'f1-score': 0.7261904761904762, 'support': 23}, 'weighted avg': {'precision': 0.7391304347826086, 'recall': 0.7391304347826086, 'f1-score': 0.7391304347826086, 'support': 23}}\n",
      "Number of fold:  4\n",
      "{'0.0': {'precision': 0.7142857142857143, 'recall': 0.7142857142857143, 'f1-score': 0.7142857142857143, 'support': 14}, '1.0': {'precision': 0.5555555555555556, 'recall': 0.5555555555555556, 'f1-score': 0.5555555555555556, 'support': 9}, 'accuracy': 0.6521739130434783, 'macro avg': {'precision': 0.6349206349206349, 'recall': 0.6349206349206349, 'f1-score': 0.6349206349206349, 'support': 23}, 'weighted avg': {'precision': 0.6521739130434783, 'recall': 0.6521739130434783, 'f1-score': 0.6521739130434783, 'support': 23}}\n",
      "Number of fold:  5\n",
      "{'0.0': {'precision': 0.7777777777777778, 'recall': 0.5833333333333334, 'f1-score': 0.6666666666666666, 'support': 12}, '1.0': {'precision': 0.6428571428571429, 'recall': 0.8181818181818182, 'f1-score': 0.7200000000000001, 'support': 11}, 'accuracy': 0.6956521739130435, 'macro avg': {'precision': 0.7103174603174603, 'recall': 0.7007575757575758, 'f1-score': 0.6933333333333334, 'support': 23}, 'weighted avg': {'precision': 0.7132505175983437, 'recall': 0.6956521739130435, 'f1-score': 0.6921739130434783, 'support': 23}}\n",
      "Cross Validation Accuracy Scores:  [0.67, 0.65, 0.74, 0.65, 0.7]\n",
      "Average CV Score:  0.682\n"
     ]
    }
   ],
   "source": [
    "('  KNN')\n",
    "cross_validation(data1.features, data1.ground_truth, train_func=train_kNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fold:  1\n",
      "{'0.0': {'precision': 0.5833333333333334, 'recall': 0.7, 'f1-score': 0.6363636363636365, 'support': 10}, '1.0': {'precision': 0.75, 'recall': 0.6428571428571429, 'f1-score': 0.6923076923076924, 'support': 14}, 'accuracy': 0.6666666666666666, 'macro avg': {'precision': 0.6666666666666667, 'recall': 0.6714285714285715, 'f1-score': 0.6643356643356644, 'support': 24}, 'weighted avg': {'precision': 0.6805555555555557, 'recall': 0.6666666666666666, 'f1-score': 0.6689976689976692, 'support': 24}}\n",
      "Number of fold:  2\n",
      "{'0.0': {'precision': 0.7142857142857143, 'recall': 0.3333333333333333, 'f1-score': 0.4545454545454545, 'support': 15}, '1.0': {'precision': 0.375, 'recall': 0.75, 'f1-score': 0.5, 'support': 8}, 'accuracy': 0.4782608695652174, 'macro avg': {'precision': 0.5446428571428572, 'recall': 0.5416666666666666, 'f1-score': 0.47727272727272724, 'support': 23}, 'weighted avg': {'precision': 0.5962732919254659, 'recall': 0.4782608695652174, 'f1-score': 0.4703557312252964, 'support': 23}}\n",
      "Number of fold:  3\n",
      "{'0.0': {'precision': 0.7142857142857143, 'recall': 0.8333333333333334, 'f1-score': 0.7692307692307692, 'support': 6}, '1.0': {'precision': 0.9375, 'recall': 0.8823529411764706, 'f1-score': 0.9090909090909091, 'support': 17}, 'accuracy': 0.8695652173913043, 'macro avg': {'precision': 0.8258928571428572, 'recall': 0.857843137254902, 'f1-score': 0.8391608391608392, 'support': 23}, 'weighted avg': {'precision': 0.8792701863354037, 'recall': 0.8695652173913043, 'f1-score': 0.8726056552143507, 'support': 23}}\n",
      "Number of fold:  4\n",
      "{'0.0': {'precision': 0.875, 'recall': 0.5384615384615384, 'f1-score': 0.6666666666666667, 'support': 13}, '1.0': {'precision': 0.6, 'recall': 0.9, 'f1-score': 0.7200000000000001, 'support': 10}, 'accuracy': 0.6956521739130435, 'macro avg': {'precision': 0.7375, 'recall': 0.7192307692307692, 'f1-score': 0.6933333333333334, 'support': 23}, 'weighted avg': {'precision': 0.7554347826086957, 'recall': 0.6956521739130435, 'f1-score': 0.6898550724637682, 'support': 23}}\n",
      "Number of fold:  5\n",
      "{'0.0': {'precision': 0.75, 'recall': 0.75, 'f1-score': 0.75, 'support': 12}, '1.0': {'precision': 0.7272727272727273, 'recall': 0.7272727272727273, 'f1-score': 0.7272727272727273, 'support': 11}, 'accuracy': 0.7391304347826086, 'macro avg': {'precision': 0.7386363636363636, 'recall': 0.7386363636363636, 'f1-score': 0.7386363636363636, 'support': 23}, 'weighted avg': {'precision': 0.7391304347826086, 'recall': 0.7391304347826086, 'f1-score': 0.7391304347826086, 'support': 23}}\n",
      "Cross Validation Accuracy Scores:  [0.67, 0.48, 0.87, 0.7, 0.74]\n",
      "Average CV Score:  0.692\n"
     ]
    }
   ],
   "source": [
    "('  KNN')\n",
    "cross_validation(data1.features, data1.ground_truth, train_func=train_kNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fold:  1\n",
      "{'0.0': {'precision': 0.6666666666666666, 'recall': 0.6153846153846154, 'f1-score': 0.64, 'support': 13.0}, '1.0': {'precision': 0.5833333333333334, 'recall': 0.6363636363636364, 'f1-score': 0.6086956521739131, 'support': 11.0}, 'accuracy': 0.625, 'macro avg': {'precision': 0.625, 'recall': 0.6258741258741258, 'f1-score': 0.6243478260869566, 'support': 24.0}, 'weighted avg': {'precision': 0.6284722222222222, 'recall': 0.625, 'f1-score': 0.6256521739130435, 'support': 24.0}}\n",
      "Number of fold:  2\n",
      "{'0.0': {'precision': 0.6666666666666666, 'recall': 0.9090909090909091, 'f1-score': 0.7692307692307692, 'support': 11.0}, '1.0': {'precision': 0.875, 'recall': 0.5833333333333334, 'f1-score': 0.7000000000000001, 'support': 12.0}, 'accuracy': 0.7391304347826086, 'macro avg': {'precision': 0.7708333333333333, 'recall': 0.7462121212121212, 'f1-score': 0.7346153846153847, 'support': 23.0}, 'weighted avg': {'precision': 0.7753623188405797, 'recall': 0.7391304347826086, 'f1-score': 0.7331103678929765, 'support': 23.0}}\n",
      "Number of fold:  3\n",
      "{'0.0': {'precision': 0.6, 'recall': 1.0, 'f1-score': 0.7499999999999999, 'support': 9.0}, '1.0': {'precision': 1.0, 'recall': 0.5714285714285714, 'f1-score': 0.7272727272727273, 'support': 14.0}, 'accuracy': 0.7391304347826086, 'macro avg': {'precision': 0.8, 'recall': 0.7857142857142857, 'f1-score': 0.7386363636363635, 'support': 23.0}, 'weighted avg': {'precision': 0.8434782608695651, 'recall': 0.7391304347826086, 'f1-score': 0.7361660079051383, 'support': 23.0}}\n",
      "Number of fold:  4\n",
      "{'0.0': {'precision': 0.7272727272727273, 'recall': 0.6666666666666666, 'f1-score': 0.6956521739130435, 'support': 12.0}, '1.0': {'precision': 0.6666666666666666, 'recall': 0.7272727272727273, 'f1-score': 0.6956521739130435, 'support': 11.0}, 'accuracy': 0.6956521739130435, 'macro avg': {'precision': 0.696969696969697, 'recall': 0.696969696969697, 'f1-score': 0.6956521739130435, 'support': 23.0}, 'weighted avg': {'precision': 0.6982872200263504, 'recall': 0.6956521739130435, 'f1-score': 0.6956521739130435, 'support': 23.0}}\n",
      "Number of fold:  5\n",
      "{'0.0': {'precision': 0.6153846153846154, 'recall': 0.7272727272727273, 'f1-score': 0.6666666666666667, 'support': 11.0}, '1.0': {'precision': 0.7, 'recall': 0.5833333333333334, 'f1-score': 0.6363636363636365, 'support': 12.0}, 'accuracy': 0.6521739130434783, 'macro avg': {'precision': 0.6576923076923077, 'recall': 0.6553030303030303, 'f1-score': 0.6515151515151516, 'support': 23.0}, 'weighted avg': {'precision': 0.6595317725752509, 'recall': 0.6521739130434783, 'f1-score': 0.6508563899868249, 'support': 23.0}}\n",
      "Cross Validation Accuracy Scores:  [0.62, 0.74, 0.74, 0.7, 0.65]\n",
      "Average CV Score:  0.69\n"
     ]
    }
   ],
   "source": [
    "('  SVM')\n",
    "cross_validation(data1.features, data1.ground_truth, train_func=train_SVM_model, save_opt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fold:  1\n",
      "{'0.0': {'precision': 0.6153846153846154, 'recall': 1.0, 'f1-score': 0.761904761904762, 'support': 8}, '1.0': {'precision': 1.0, 'recall': 0.6875, 'f1-score': 0.8148148148148148, 'support': 16}, 'accuracy': 0.7916666666666666, 'macro avg': {'precision': 0.8076923076923077, 'recall': 0.84375, 'f1-score': 0.7883597883597884, 'support': 24}, 'weighted avg': {'precision': 0.8717948717948718, 'recall': 0.7916666666666666, 'f1-score': 0.7971781305114639, 'support': 24}}\n",
      "Number of fold:  2\n",
      "{'0.0': {'precision': 0.6666666666666666, 'recall': 0.46153846153846156, 'f1-score': 0.5454545454545455, 'support': 13}, '1.0': {'precision': 0.5, 'recall': 0.7, 'f1-score': 0.5833333333333334, 'support': 10}, 'accuracy': 0.5652173913043478, 'macro avg': {'precision': 0.5833333333333333, 'recall': 0.5807692307692307, 'f1-score': 0.5643939393939394, 'support': 23}, 'weighted avg': {'precision': 0.5942028985507246, 'recall': 0.5652173913043478, 'f1-score': 0.5619235836627141, 'support': 23}}\n",
      "Number of fold:  3\n",
      "{'0.0': {'precision': 0.7142857142857143, 'recall': 0.7692307692307693, 'f1-score': 0.7407407407407408, 'support': 13}, '1.0': {'precision': 0.6666666666666666, 'recall': 0.6, 'f1-score': 0.631578947368421, 'support': 10}, 'accuracy': 0.6956521739130435, 'macro avg': {'precision': 0.6904761904761905, 'recall': 0.6846153846153846, 'f1-score': 0.6861598440545809, 'support': 23}, 'weighted avg': {'precision': 0.6935817805383023, 'recall': 0.6956521739130435, 'f1-score': 0.6932790914484278, 'support': 23}}\n",
      "Number of fold:  4\n",
      "{'0.0': {'precision': 0.7, 'recall': 0.875, 'f1-score': 0.7777777777777777, 'support': 8}, '1.0': {'precision': 0.9230769230769231, 'recall': 0.8, 'f1-score': 0.8571428571428571, 'support': 15}, 'accuracy': 0.8260869565217391, 'macro avg': {'precision': 0.8115384615384615, 'recall': 0.8375, 'f1-score': 0.8174603174603174, 'support': 23}, 'weighted avg': {'precision': 0.845484949832776, 'recall': 0.8260869565217391, 'f1-score': 0.8295376121463076, 'support': 23}}\n",
      "Number of fold:  5\n",
      "{'0.0': {'precision': 0.8181818181818182, 'recall': 0.6428571428571429, 'f1-score': 0.7200000000000001, 'support': 14}, '1.0': {'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'f1-score': 0.6666666666666666, 'support': 9}, 'accuracy': 0.6956521739130435, 'macro avg': {'precision': 0.7007575757575758, 'recall': 0.7103174603174603, 'f1-score': 0.6933333333333334, 'support': 23}, 'weighted avg': {'precision': 0.7262845849802371, 'recall': 0.6956521739130435, 'f1-score': 0.6991304347826087, 'support': 23}}\n",
      "Cross Validation Accuracy Scores:  [0.79, 0.57, 0.7, 0.83, 0.7]\n",
      "Average CV Score:  0.718\n"
     ]
    }
   ],
   "source": [
    "('  SVM')\n",
    "cross_validation(data1.features, data1.ground_truth, train_func=train_SVM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.0': {'precision': 0.7142857142857143, 'recall': 0.8333333333333334, 'f1-score': 0.7692307692307692, 'support': 12}, '1.0': {'precision': 0.8, 'recall': 0.6666666666666666, 'f1-score': 0.7272727272727272, 'support': 12}, 'accuracy': 0.75, 'macro avg': {'precision': 0.7571428571428571, 'recall': 0.75, 'f1-score': 0.7482517482517481, 'support': 24}, 'weighted avg': {'precision': 0.7571428571428571, 'recall': 0.75, 'f1-score': 0.7482517482517482, 'support': 24}}\n",
      "Number of fold:  2\n",
      "{'0.0': {'precision': 0.5833333333333334, 'recall': 0.5833333333333334, 'f1-score': 0.5833333333333334, 'support': 12}, '1.0': {'precision': 0.5454545454545454, 'recall': 0.5454545454545454, 'f1-score': 0.5454545454545454, 'support': 11}, 'accuracy': 0.5652173913043478, 'macro avg': {'precision': 0.5643939393939394, 'recall': 0.5643939393939394, 'f1-score': 0.5643939393939394, 'support': 23}, 'weighted avg': {'precision': 0.5652173913043478, 'recall': 0.5652173913043478, 'f1-score': 0.5652173913043478, 'support': 23}}\n",
      "Number of fold:  3\n",
      "{'0.0': {'precision': 0.5882352941176471, 'recall': 0.9090909090909091, 'f1-score': 0.7142857142857143, 'support': 11}, '1.0': {'precision': 0.8333333333333334, 'recall': 0.4166666666666667, 'f1-score': 0.5555555555555556, 'support': 12}, 'accuracy': 0.6521739130434783, 'macro avg': {'precision': 0.7107843137254902, 'recall': 0.6628787878787878, 'f1-score': 0.6349206349206349, 'support': 23}, 'weighted avg': {'precision': 0.7161125319693094, 'recall': 0.6521739130434783, 'f1-score': 0.6314699792960663, 'support': 23}}\n",
      "Number of fold:  4\n",
      "{'0.0': {'precision': 0.7333333333333333, 'recall': 0.9166666666666666, 'f1-score': 0.8148148148148148, 'support': 12}, '1.0': {'precision': 0.875, 'recall': 0.6363636363636364, 'f1-score': 0.7368421052631579, 'support': 11}, 'accuracy': 0.782608695652174, 'macro avg': {'precision': 0.8041666666666667, 'recall': 0.7765151515151515, 'f1-score': 0.7758284600389863, 'support': 23}, 'weighted avg': {'precision': 0.801086956521739, 'recall': 0.782608695652174, 'f1-score': 0.7775235189422831, 'support': 23}}\n",
      "Number of fold:  5\n",
      "{'0.0': {'precision': 0.6, 'recall': 0.6666666666666666, 'f1-score': 0.631578947368421, 'support': 9}, '1.0': {'precision': 0.7692307692307693, 'recall': 0.7142857142857143, 'f1-score': 0.7407407407407408, 'support': 14}, 'accuracy': 0.6956521739130435, 'macro avg': {'precision': 0.6846153846153846, 'recall': 0.6904761904761905, 'f1-score': 0.6861598440545809, 'support': 23}, 'weighted avg': {'precision': 0.703010033444816, 'recall': 0.6956521739130435, 'f1-score': 0.6980252563776592, 'support': 23}}\n",
      "Cross Validation Accuracy Scores:  [0.75, 0.57, 0.65, 0.78, 0.7]\n",
      "Average CV Score:  0.6900000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "('  MLP')\n",
    "cross_validation(data1.features, data1.ground_truth, train_func=train_MLP_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, '1.0': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 12}, 'accuracy': 0.5, 'macro avg': {'precision': 0.25, 'recall': 0.5, 'f1-score': 0.3333333333333333, 'support': 24}, 'weighted avg': {'precision': 0.25, 'recall': 0.5, 'f1-score': 0.3333333333333333, 'support': 24}}\n",
      "Number of fold:  2\n",
      "{'0.0': {'precision': 0.6521739130434783, 'recall': 1.0, 'f1-score': 0.7894736842105263, 'support': 15}, '1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, 'accuracy': 0.6521739130434783, 'macro avg': {'precision': 0.32608695652173914, 'recall': 0.5, 'f1-score': 0.39473684210526316, 'support': 23}, 'weighted avg': {'precision': 0.42533081285444235, 'recall': 0.6521739130434783, 'f1-score': 0.5148741418764302, 'support': 23}}\n",
      "Number of fold:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.0': {'precision': 0.391304347826087, 'recall': 1.0, 'f1-score': 0.5625, 'support': 9}, '1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14}, 'accuracy': 0.391304347826087, 'macro avg': {'precision': 0.1956521739130435, 'recall': 0.5, 'f1-score': 0.28125, 'support': 23}, 'weighted avg': {'precision': 0.15311909262759923, 'recall': 0.391304347826087, 'f1-score': 0.22010869565217392, 'support': 23}}\n",
      "Number of fold:  4\n",
      "{'0.0': {'precision': 0.34782608695652173, 'recall': 1.0, 'f1-score': 0.5161290322580645, 'support': 8}, '1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, 'accuracy': 0.34782608695652173, 'macro avg': {'precision': 0.17391304347826086, 'recall': 0.5, 'f1-score': 0.25806451612903225, 'support': 23}, 'weighted avg': {'precision': 0.12098298676748583, 'recall': 0.34782608695652173, 'f1-score': 0.17952314165497896, 'support': 23}}\n",
      "Number of fold:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.0': {'precision': 0.5217391304347826, 'recall': 1.0, 'f1-score': 0.6857142857142856, 'support': 12}, '1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11}, 'accuracy': 0.5217391304347826, 'macro avg': {'precision': 0.2608695652173913, 'recall': 0.5, 'f1-score': 0.3428571428571428, 'support': 23}, 'weighted avg': {'precision': 0.2722117202268431, 'recall': 0.5217391304347826, 'f1-score': 0.35776397515527947, 'support': 23}}\n",
      "Cross Validation Accuracy Scores:  [0.5, 0.65, 0.39, 0.35, 0.52]\n",
      "Average CV Score:  0.48200000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "('  MLP')\n",
    "cross_validation(data1.features, data1.ground_truth, train_func=train_MLP_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data - (2. dataset TAPPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: sztuczne powiększenie zbioru grupy kontrolnej w Tappy ?\n",
    "# how many files? - this number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients with PD:  162\n",
      "Patients without PD:  55\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory_path1 = 'D:/studia_mgrEIM/master_diploma/data/tappy-keystroke-data-1.0.0/Archived_users/'\n",
    "directory_path2 = 'D:/studia_mgrEIM/master_diploma/data/tappy-keystroke-data-1.0.0/Tappy_Data/'\n",
    "\n",
    "data2 = tappyDataset(directory_path1, directory_path2, opt=0)\n",
    "data2.show_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>files</th>\n",
       "      <th>Parkinsons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ZT9ASWFCFS</td>\n",
       "      <td>[ZT9ASWFCFS_1606.txt]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ZWBPPNQCUX</td>\n",
       "      <td>[ZWBPPNQCUX_1608.txt, ZWBPPNQCUX_1612.txt]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ZWHGXDUDLG</td>\n",
       "      <td>[ZWHGXDUDLG_1703.txt]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>ZY9CCHSPF2</td>\n",
       "      <td>[ZY9CCHSPF2_1607.txt, ZY9CCHSPF2_1608.txt, ZY9...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ZYWLN4JVLA</td>\n",
       "      <td>[ZYWLN4JVLA_1701.txt]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pID                                              files  Parkinsons\n",
       "222  ZT9ASWFCFS                              [ZT9ASWFCFS_1606.txt]         1.0\n",
       "223  ZWBPPNQCUX         [ZWBPPNQCUX_1608.txt, ZWBPPNQCUX_1612.txt]         1.0\n",
       "224  ZWHGXDUDLG                              [ZWHGXDUDLG_1703.txt]         1.0\n",
       "225  ZY9CCHSPF2  [ZY9CCHSPF2_1607.txt, ZY9CCHSPF2_1608.txt, ZY9...         1.0\n",
       "226  ZYWLN4JVLA                              [ZYWLN4JVLA_1701.txt]         1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.user_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index:  0\n",
      "L:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\keystroke_module.py:478: DtypeWarning: Columns (4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, delimiter=\"\\t\", index_col=False, header=None, names=[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used\n",
      "\n",
      "Index:  1\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  2\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  3\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  4\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  5\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  6\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  7\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  8\n",
      "L:  2\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  9\n",
      "L:  6\n",
      "used\n",
      "\n",
      "Index:  10\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  11\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  12\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  13\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  14\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  15\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  16\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  17\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  18\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  19\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  20\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  21\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  22\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  23\n",
      "L:  2\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  24\n",
      "L:  7\n",
      "used\n",
      "\n",
      "Index:  25\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  26\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  27\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  28\n",
      "L:  5\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  4\n",
      "\n",
      "Index:  29\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  30\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  31\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  32\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  33\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  34\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  35\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  36\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  37\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  38\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  39\n",
      "L:  4\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  3\n",
      "\n",
      "Index:  40\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  41\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  42\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  43\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  44\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  45\n",
      "L:  3\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  2\n",
      "\n",
      "Index:  46\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  47\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  48\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  49\n",
      "L:  2\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  50\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  51\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  52\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  53\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  54\n",
      "L:  7\n",
      "used\n",
      "\n",
      "Index:  55\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  56\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  57\n",
      "L:  4\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  3\n",
      "\n",
      "Index:  58\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  59\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  60\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  61\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  62\n",
      "L:  7\n",
      "used\n",
      "\n",
      "Index:  63\n",
      "L:  2\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  64\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  65\n",
      "L:  2\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  66\n",
      "L:  2\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  67\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  68\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  69\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  70\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  71\n",
      "L:  7\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  6\n",
      "\n",
      "Index:  72\n",
      "L:  7\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  6\n",
      "\n",
      "Index:  73\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  74\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  75\n",
      "L:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\keystroke_module.py:478: DtypeWarning: Columns (4,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, delimiter=\"\\t\", index_col=False, header=None, names=[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used\n",
      "\n",
      "Index:  76\n",
      "L:  7\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  6\n",
      "\n",
      "Index:  77\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  78\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  79\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  80\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  81\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  82\n",
      "L:  7\n",
      "used\n",
      "\n",
      "Index:  83\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  84\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  85\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  86\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  87\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  88\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  89\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  90\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  91\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  92\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  93\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  94\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  95\n",
      "L:  7\n",
      "used\n",
      "\n",
      "Index:  96\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  97\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  98\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  99\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  100\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  101\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  102\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  103\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  104\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  105\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  106\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  107\n",
      "L:  2\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  108\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  109\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  110\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  111\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  112\n",
      "L:  9\n",
      "used\n",
      "\n",
      "Index:  113\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  114\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  115\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  116\n",
      "L:  5\n",
      "used\n",
      "\n",
      "Index:  117\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  118\n",
      "L:  6\n",
      "used\n",
      "\n",
      "Index:  119\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  120\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  121\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  122\n",
      "L:  5\n",
      "used\n",
      "\n",
      "Index:  123\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  124\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  125\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  126\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  127\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  128\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  129\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  130\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  131\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  132\n",
      "L:  9\n",
      "used\n",
      "\n",
      "Index:  133\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  134\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  135\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  136\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  137\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  138\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  139\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  140\n",
      "L:  6\n",
      "used\n",
      "\n",
      "Index:  141\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  142\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  143\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  144\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  145\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  146\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  147\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  148\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  149\n",
      "L:  5\n",
      "used\n",
      "\n",
      "Index:  150\n",
      "L:  3\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  2\n",
      "\n",
      "Index:  151\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  152\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  153\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  154\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  155\n",
      "L:  2\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  156\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  157\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  158\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  159\n",
      "L:  6\n",
      "used\n",
      "\n",
      "Index:  160\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  161\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  162\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  163\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  164\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  165\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  166\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  167\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  168\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  169\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  170\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  171\n",
      "L:  5\n",
      "used\n",
      "\n",
      "Index:  172\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  173\n",
      "L:  10\n",
      "used\n",
      "\n",
      "Index:  174\n",
      "L:  2\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  175\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  176\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  177\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  178\n",
      "L:  3\n",
      "used\n",
      "\n",
      "Index:  179\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  180\n",
      "L:  2\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  181\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  182\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  183\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  184\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  185\n",
      "L:  1\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  186\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  187\n",
      "L:  6\n",
      "used\n",
      "\n",
      "Index:  188\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  189\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  190\n",
      "L:  2\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  191\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  192\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  193\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  194\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  195\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  196\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  197\n",
      "L:  10\n",
      "used\n",
      "\n",
      "Index:  198\n",
      "L:  2\n",
      "Record not useful, with gt:  0.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  199\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  200\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  201\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  202\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  203\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  204\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  205\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  206\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  207\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  208\n",
      "L:  4\n",
      "used\n",
      "\n",
      "Index:  209\n",
      "L:  2\n",
      "used\n",
      "\n",
      "Index:  210\n",
      "L:  1\n",
      "used\n",
      "\n",
      "Index:  211\n",
      "L:  8\n",
      "used\n",
      "\n",
      "Index:  212\n",
      "L:  1\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  213\n",
      "L:  2\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  1\n",
      "\n",
      "Index:  214\n",
      "L:  1\n",
      "Warning was raised as an exception!\n",
      "Warning was raised as an exception!\n",
      "Record not useful, with gt:  1.0\n",
      "Counter:  0\n",
      "\n",
      "Index:  215\n",
      "L:  7\n",
      "used\n",
      "\n",
      "Index:  216\n",
      "L:  1\n",
      "used\n",
      "     SUCCESS!!!\n"
     ]
    }
   ],
   "source": [
    "data2.prepare_dataset(directory_path2, feature_extract=2)\n",
    "# print(data2.trainset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 22)\n"
     ]
    }
   ],
   "source": [
    "print(data2.features.shape)\n",
    "signiX = data2.features\n",
    "signiY = data2.user_info['Parkinsons'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_features.npy', data2.features)\n",
    "np.save('data_gt.npy', data2.user_info['Parkinsons'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signiX = np.load('data_features.npy')\n",
    "signiY = np.load('data_gt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 40\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | layers    | Sequential     | 1.3 K \n",
      "1 | ce        | BCELoss        | 0     \n",
      "2 | train_acc | BinaryAccuracy | 0     \n",
      "3 | test_acc  | BinaryAccuracy | 0     \n",
      "---------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "d:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/117 [00:00<?, ?it/s] tensor([[1.]])     tensor([[0.5774]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]])     tensor(0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Predictions and targets are expected to have the same shape, but got torch.Size([]) and torch.Size([1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\processing.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/studia_mgrEIM/master_diploma/repo/masterdiploma/processing.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# + standaryzację danych \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/studia_mgrEIM/master_diploma/repo/masterdiploma/processing.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(signiX, signiY, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/studia_mgrEIM/master_diploma/repo/masterdiploma/processing.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trainer \u001b[39m=\u001b[39m train_architecture(X_train,y_train,seed\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,max_epoch_train \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\kmodule\\keystroke_module.py:347\u001b[0m, in \u001b[0;36mtrain_architecture\u001b[1;34m(X, Y, seed, max_epoch_train)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[39m# trainer = pl.Trainer(auto_scale_batch_size='power',\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     \u001b[39m#                         deterministic=True, max_epochs=max_epoch_train)\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39mmax_epoch_train)\n\u001b[1;32m--> 347\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(mlp, train_dataloader)\n\u001b[0;32m    348\u001b[0m \u001b[39mreturn\u001b[39;00m trainer\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[1;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    534\u001b[0m )\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    567\u001b[0m     ckpt_path,\n\u001b[0;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    570\u001b[0m )\n\u001b[1;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1021\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1023\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1024\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[0;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[0;32m    354\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[0;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[0;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:219\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    218\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[0;32m    220\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:188\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         closure()\n\u001b[0;32m    183\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[0;32m    190\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[0;32m    191\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:266\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[0;32m    265\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[0;32m    267\u001b[0m     trainer,\n\u001b[0;32m    268\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    269\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[0;32m    270\u001b[0m     batch_idx,\n\u001b[0;32m    271\u001b[0m     optimizer,\n\u001b[0;32m    272\u001b[0m     train_step_and_backward_closure,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:146\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 146\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    148\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    149\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1276\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[0;32m   1239\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1240\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1243\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1244\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[39m    calls the optimizer.\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1276\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:161\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy\u001b[39m.\u001b[39moptimizer_step(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer, closure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[0;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:231\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[1;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39moptimizer_step(optimizer, model\u001b[39m=\u001b[39mmodel, closure\u001b[39m=\u001b[39mclosure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:116\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 116\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39mstep(closure\u001b[39m=\u001b[39mclosure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torch\\optim\\adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> 121\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    124\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:103\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[0;32m     92\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     93\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[0;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m     96\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     97\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:142\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclosure(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:128\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39menable_grad()\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 128\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[0;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[0;32m    314\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    316\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[0;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_result_cls\u001b[39m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[39m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 294\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    297\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:380\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[0;32m    379\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[1;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\myMLP.py:42\u001b[0m, in \u001b[0;36mMLP.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     40\u001b[0m preds \u001b[39m=\u001b[39m argmax(output)\n\u001b[0;32m     41\u001b[0m \u001b[39mprint\u001b[39m(labels, \u001b[39m'\u001b[39m\u001b[39m   \u001b[39m\u001b[39m'\u001b[39m, preds)\n\u001b[1;32m---> 42\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_acc\u001b[39m.\u001b[39;49mupdate(preds, labels)\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mtrain_acc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_acc\u001b[39m.\u001b[39mcompute(), prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torchmetrics\\metric.py:467\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[0;32m    460\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    465\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m device corresponds to the device of the input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    466\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_on_cpu:\n\u001b[0;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_move_list_states_to_cpu()\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torchmetrics\\metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[0;32m    456\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m         update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    458\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    459\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:181\u001b[0m, in \u001b[0;36mBinaryStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 181\u001b[0m     _binary_stat_scores_tensor_validation(preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultidim_average, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index)\n\u001b[0;32m    182\u001b[0m preds, target \u001b[39m=\u001b[39m _binary_stat_scores_format(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index)\n\u001b[0;32m    183\u001b[0m tp, fp, tn, fn \u001b[39m=\u001b[39m _binary_stat_scores_update(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultidim_average)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:63\u001b[0m, in \u001b[0;36m_binary_stat_scores_tensor_validation\u001b[1;34m(preds, target, multidim_average, ignore_index)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Validate tensor input.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[39m- tensors have to be of same shape\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m# Check that they have same shape\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m _check_same_shape(preds, target)\n\u001b[0;32m     65\u001b[0m \u001b[39m# Check that target only contains [0,1] values or value in ignore_index\u001b[39;00m\n\u001b[0;32m     66\u001b[0m unique_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munique(target)\n",
      "File \u001b[1;32md:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\pro-env\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:42\u001b[0m, in \u001b[0;36m_check_same_shape\u001b[1;34m(preds, target)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check that predictions and target have the same shape, else raise error.\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m preds\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m target\u001b[39m.\u001b[39mshape:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     43\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredictions and targets are expected to have the same shape, but got \u001b[39m\u001b[39m{\u001b[39;00mpreds\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Predictions and targets are expected to have the same shape, but got torch.Size([]) and torch.Size([1, 1])."
     ]
    }
   ],
   "source": [
    "# + standaryzację danych \n",
    "X_train, X_test, y_train, y_test = train_test_split(signiX, signiY, test_size=0.3, random_state=2)\n",
    "trainer = train_architecture(X_train,y_train,seed=40,max_epoch_train = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\checkpoint_connector.py:124: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at d:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\lightning_logs\\version_0\\checkpoints\\epoch=49-step=5850.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from checkpoint at d:\\studia_mgrEIM\\master_diploma\\repo\\masterdiploma\\lightning_logs\\version_0\\checkpoints\\epoch=49-step=5850.ckpt\n",
      "d:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a1f2e4997f47b79ea30fb211ad2e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7493432760238647\n",
      "        test_loss           0.5883905291557312\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "test_architecture(trainer,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = torch.round(output).detach().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "d:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39196bcb5a94458eb6899e02fd92ab9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6817317008972168\n",
      "        test_loss           0.5722163319587708\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5722163319587708, 'test_acc': 0.6817317008972168}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/Lightning-AI/lightning/issues/924\n",
    "model_test = MLP.load_from_checkpoint('lightning_logs/version_15/checkpoints/epoch=39-step=6720.ckpt')\n",
    "trainer = pl.Trainer()  \n",
    "trainer.test(model_test,dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3076923076923077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.33      0.31        12\n",
      "         1.0       0.33      0.29      0.31        14\n",
      "\n",
      "    accuracy                           0.31        26\n",
      "   macro avg       0.31      0.31      0.31        26\n",
      "weighted avg       0.31      0.31      0.31        26\n",
      "\n",
      "0.4230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.67      0.52        12\n",
      "         1.0       0.43      0.21      0.29        14\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.42      0.44      0.40        26\n",
      "weighted avg       0.43      0.42      0.39        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sampling_imbalanced_data(X, y, opt='under'):\n",
    "    if str(opt) == 'under':\n",
    "        rus = RandomUnderSampler(random_state=None)\n",
    "        X_resampl, y_resampl = rus.fit_resample(X, y)\n",
    "    else:\n",
    "        ros = RandomOverSampler(random_state=None)\n",
    "        X_resampl, y_resampl = ros.fit_resample(X, y)\n",
    "    return X_resampl, y_resampl\n",
    "    \n",
    "\n",
    "X_resampl, y_resampl = sampling_imbalanced_data(signiX, signiY, opt='under')\n",
    "trainset, testset, train_ground_truth, test_ground_truth = train_test_split(\n",
    "    X_resampl, y_resampl, test_size=0.3, shuffle=True, random_state=42)\n",
    "    # signiX, signiY, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "('  KNN')\n",
    "model = train_kNN_model(trainset, train_ground_truth)\n",
    "predictions, acc_val, rep = test_selected_model(testset, test_ground_truth, model)\n",
    "\n",
    "('  SVM')\n",
    "model = train_SVM_model(trainset, train_ground_truth)\n",
    "predictions, acc_val, rep = test_selected_model(testset, test_ground_truth, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
